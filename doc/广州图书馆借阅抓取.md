搭建自己的网站的时候，想把自己读过借过的书都想记录一下，大学也做过自己学校的借书记录的爬取，但是数据库删掉了==，只保留一张截图。所以还是要好好珍惜自己阅读的日子吧，记录自己的借书记录————[广州图书馆](http://www.gzlib.gov.cn/)，现在代码已经放在服务器上定时运行，结果查看[我的网站（关于我）页面](http://www.wenzhihuai.com/aboutme.html)。整个代码采用HttpClient，存储放在MySql，定时使用Spring自带的Schedule，下面是抓取的过程。

### 1.页面跳转过程
一般都是进入首页[http://www.gzlib.gov.cn/](http://www.gzlib.gov.cn/)，点击进登陆页面，然后输入账号密码。表面上看起来没什么特别之处，实际上模拟登陆的时候不仅仅是向链接post一个请求那么简单，得到的response要么跳回登陆页面，要么无限制重定向。
<div align="center">

![](http://image.wenzhihuai.com/images/20171013042700.png)

</div>

事实上，它做了跨域单点登录，如下图，广州图书馆的网址为：www.gzlib.gov.cn，而登陆的网址为：login.gzlib.gov.cn。原理网上很多人都讲的很好了，可以看看这篇文章[SSO单点登录之跨域问题](http://www.cnblogs.com/tibos/p/5354000.html)。

<div align="center">

![](http://image.wenzhihuai.com/images/20171013043304.png)

</div>

### 2.处理方法
解决办法不难，只要先模拟访问一下首页即可获取图书馆的session，python的获取代码如：session.get("http://www.gzlib.gov.cn/")，打印cookie之后如下：
```html
[<Cookie JSESSIONID=19E2DDED4FE7756AA9161A52737D6B8E for .gzlib.gov.cn/>, <Cookie JSESSIONID=19E2DDED4FE7756AA9161A52737D6B8E for www.gzlib.gov.cn/>, <Cookie clientlanguage=zh_CN for www.gzlib.gov.cn/>]
```

整个登陆抓取的流程如下：
<div align="center">

![](http://image.wenzhihuai.com/images/20171013052853.png)

</div>



### 3.
<div align="center">

![](http://image.wenzhihuai.com/images/20171010062602.png)

</div>

```python
import urllib.parse
import requests
from bs4 import BeautifulSoup

session = requests.session()
session.get("http://www.gzlib.gov.cn/")
print(session.cookies)
print(session.headers)
session.headers.update(
    {"Referer": "http://www.gzlib.gov.cn/member/historyLoanList.jspx",
     "origin": "http://login.gzlib.gov.cn",
     'Content-Type': 'application/x-www-form-urlencoded',
     'host': 'www.gzlib.gov.cn',
     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'
     }
)
baseURL = "http://login.gzlib.gov.cn/sso-server/login?service=http%3A%2F%2Fwww.gzlib.gov.cn%2Flogin.jspx%3FreturnUrl%3Dhttp%253A%252F%252Fwww.gzlib.gov.cn%252F%26locale%3Dzh_CN&appId=www.gzlib.gov.cn&locale=zh_CN"
soup = BeautifulSoup(session.get(baseURL).text, "html.parser")
lt = soup.select("form")[0].find(attrs={'name': 'lt'})['value']
postdict = {"username": "your card id",
            "password": "your password",
            "_eventId": "submit",
            "lt": lt
            }
postdata = urllib.parse.urlencode(postdict)
session.post(baseURL, postdata)
print(session.get("http://www.gzlib.gov.cn/").text)
```